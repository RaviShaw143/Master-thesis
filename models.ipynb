import pandas as pd
import os
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import make_scorer, accuracy_score, f1_score
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score
from sklearn.model_selection import cross_val_score

featuresFilePath = os.path.abspath(os.path.join("Desktop", "Code", "LabelFiles", "YouTubeDataFeaturesWithOutput.csv"))

features = pd.read_csv(featuresFilePath)

x = features.iloc[:,0:10493].values

y  = features["output"][:].values

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.10, random_state = 0)
print("Number of features before using PCA:" + str(len(x[0])))

#standardize the data
scaler = StandardScaler()
#Fit on train set only
scaler.fit(x_train)

#Applying transform on train and test set both
x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)

X = scaler.transform(x)


#choose the minimum number of principal components such that 95% of the variance is retained
pca = PCA(.85)

#fittng PCA on the total number of Features
pca.fit(x_train)
pca.fit(X)

#applying the mapping to train and test sets
x_train = pca.transform(x_train)
x_test = pca.transform(x_test)
X = pca.transform(X)

print("Number of features after using PCA:" + str(len(x_train[0])))
print("Number of features after using PCA:" + str(len(X[0])))

#Instances of model
logisticRegr = LogisticRegression(solver = 'lbfgs')


logisticRegr.fit(x_train, y_train)

predictions = logisticRegr.predict(x_test)

print(logisticRegr.score(x_test, y_test))

accuracy =(predictions==y_test).mean()

from sklearn.metrics import precision_recall_fscore_support
print(precision_recall_fscore_support(y_test, predictions, average='micro'))




from sklearn import svm
clf = svm.SVC(probability=True, kernel="linear", class_weight="balanced", decision_function_shape = "ovo")
#clf.fit(X, y) 
scores = cross_val_score(clf, X, y, cv=5)
#predictionss = clf.predict(x_test)
print(scores) 




